{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf27f8d-d049-4f89-b52c-cf2cae2ee078",
   "metadata": {
    "id": "ddf27f8d-d049-4f89-b52c-cf2cae2ee078"
   },
   "source": [
    "# ***Group 7 Capstone Notebook***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5d85a-a78a-48dd-baa1-97cf0fbdcf2b",
   "metadata": {
    "id": "a7d5d85a-a78a-48dd-baa1-97cf0fbdcf2b"
   },
   "source": [
    "## Data Loading, Pre-Processing, and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59435da8-88a6-4737-adf8-1e8ec5d0ef8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59435da8-88a6-4737-adf8-1e8ec5d0ef8b",
    "outputId": "a7278b4e-aaf7-41ce-d24a-c11b163a020d"
   },
   "outputs": [],
   "source": [
    "# pip install mne==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f24e008-cbc3-4e71-840e-277a56e16b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install antropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbce0a85-cdc2-4d44-aea4-22c1cd7e5ffd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbce0a85-cdc2-4d44-aea4-22c1cd7e5ffd",
    "outputId": "9acb22c4-6c7a-45ad-fe80-70f6459f7dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 600 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 1: Normal 600 epochs, Fatigue 601 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 600 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 2: Normal 600 epochs, Fatigue 601 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "603 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 603 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "603 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 603 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 3: Normal 603 epochs, Fatigue 603 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "602 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 602 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 4: Normal 601 epochs, Fatigue 602 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 600 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 5: Normal 601 epochs, Fatigue 600 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "602 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 602 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 6: Normal 601 epochs, Fatigue 602 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 7: Normal 601 epochs, Fatigue 601 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 8: Normal 601 epochs, Fatigue 601 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "602 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 602 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 9: Normal 601 epochs, Fatigue 602 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 600 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 600 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 10: Normal 600 epochs, Fatigue 600 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 601 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 11: Normal 601 epochs, Fatigue 601 epochs\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 600 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "602 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 602 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Processed Subject 12: Normal 600 epochs, Fatigue 602 epochs\n",
      "PSD Features shape: (14426, 40), Labels shape: (14426,)\n",
      "Power Spectral Density Features\n",
      "Training data shape: (11540, 40), Testing data shape: (2886, 40)\n",
      "\n",
      "Spectral Entropy Features shape: (14426, 40), Labels shape: (14426,)\n",
      "Spectral Entropy Features\n",
      "Training data shape: (11540, 40), Testing data shape: (2886, 40)\n",
      "\n",
      "PSD and Spectral Entropy Features shape: (14426, 80), Labels shape: (14426,)\n",
      "Power Spectral Density and Spectral Entropy Features\n",
      "Training data shape: (11540, 80), Testing data shape: (2886, 80)\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from antropy import spectral_entropy, app_entropy, sample_entropy\n",
    "import warnings\n",
    "warnings. filterwarnings('ignore')\n",
    "\n",
    "# Function for Data Visualization\n",
    "def plot_eeg(data_normal, data_fatigue, title, time, channels, n_channels=5):\n",
    "    fig, axes = plt.subplots(n_channels, 1, figsize=(10, 7))\n",
    "    fig.canvas.manager.set_window_title(title) # Set the window title\n",
    "\n",
    "    #Plot the Corresponding Data for Normal and Fatigue\n",
    "    for i in range(n_channels):\n",
    "        axes[i].plot(time, data_normal[i], label=f'{channels[i]} - Normal', color='blue', alpha=0.7)\n",
    "        axes[i].plot(time, data_fatigue[i], label=f'{channels[i]} - Sleepy', color='orange', alpha=0.7)\n",
    "        axes[i].set_ylabel('Amplitude (ÂµV)')\n",
    "        axes[i].legend(loc='upper right', fontsize=8)\n",
    "        if i == n_channels - 1:\n",
    "            axes[i].set_xlabel('Time (s)')\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout  \n",
    "    plt.show()\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "X_features = []  # To store Power Spectral Density (PSD) and Spectral Entropy features\n",
    "y_features = []  # To store labels\n",
    "X_psd = []       # To store Power Spectral Density features only\n",
    "X_sp_ent = []    # To store Spectral Entropy features only\n",
    "\n",
    "# Loop over all subjects\n",
    "for i in range(1, 13):\n",
    "    try:\n",
    "        # DATA LOADING\n",
    "        # Define file paths\n",
    "        normal_file = f\"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Capstone\\\\{i}\\\\{i}\\\\Normal state.cnt\"\n",
    "        fatigue_file = f\"C:\\\\Users\\\\ASUS\\\\Desktop\\\\Capstone\\\\{i}\\\\{i}\\\\Fatigue state.cnt\"\n",
    "\n",
    "        # Read EEG data for both normal and fatigue states\n",
    "        raw_normal = mne.io.read_raw_cnt(normal_file, preload=True, verbose=False)\n",
    "        raw_fatigue = mne.io.read_raw_cnt(fatigue_file, preload=True, verbose=False)\n",
    "        channels = raw_normal.ch_names\n",
    "        sfreq = raw_normal.info['sfreq']\n",
    "        min_samples = min(raw_normal.get_data().shape[1], raw_fatigue.get_data().shape[1])\n",
    "        time = np.linspace(0, min_samples / sfreq, min_samples)\n",
    "\n",
    "        # Plot Raw EEG\n",
    "        # Creates a Separate Window\n",
    "        %matplotlib qt \n",
    "        plot_eeg(raw_normal.get_data()[:, :min_samples], raw_fatigue.get_data()[:, :min_samples], title=f'Raw EEG Subject {i}', time=time, channels=channels)\n",
    "        \n",
    "        # DATA PRE-PROCESSING\n",
    "        # Apply Notch filter to remove 50 Hz line noise\n",
    "        raw_normal.notch_filter(50, fir_design='firwin')\n",
    "        raw_fatigue.notch_filter(50, fir_design='firwin')\n",
    "        \n",
    "        # Apply bandpass filter (0.15 Hz to 45 Hz)\n",
    "        raw_normal.filter(0.15, 45, fir_design='firwin')\n",
    "        raw_fatigue.filter(0.15, 45, fir_design='firwin')\n",
    "        min_samples = min(raw_normal.get_data().shape[1], raw_fatigue.get_data().shape[1])\n",
    "        time = np.linspace(0, min_samples / sfreq, min_samples)\n",
    "\n",
    "        # Plot Pre-Processed EEG\n",
    "        # Creates a Separate Window\n",
    "        %matplotlib qt \n",
    "        plot_eeg(raw_normal.get_data()[:, :min_samples], raw_fatigue.get_data()[:, :min_samples], title=f'Pre-Processed EEG Subject {i}', time=time, channels=channels)\n",
    "\n",
    "        # Generate 1-second epochs\n",
    "        epochs_normal = mne.make_fixed_length_epochs(raw_normal, duration=1, preload=True)\n",
    "        epochs_fatigue = mne.make_fixed_length_epochs(raw_fatigue, duration=1, preload=True)\n",
    "\n",
    "        # FEATURE EXTRACTION\n",
    "        # Extract Power Spectral Density (PSD) features\n",
    "        psd_normal, freqs = mne.time_frequency.psd_multitaper(epochs_normal, fmin=0.15, fmax=45)\n",
    "        psd_fatigue, _ = mne.time_frequency.psd_multitaper(epochs_fatigue, fmin=0.15, fmax=45)\n",
    "\n",
    "        # Extract Spectral Entropy features\n",
    "        sfreq = raw_normal.info['sfreq']  # Sampling frequency\n",
    "        sp_entropy_normal = spectral_entropy(epochs_normal, sfreq, method=\"welch\", normalize=True)\n",
    "        sp_entropy_fatigue = spectral_entropy(epochs_fatigue, sfreq, method=\"welch\", normalize=True)\n",
    "        \n",
    "        # Create labels\n",
    "        y_normal = np.zeros(psd_normal.shape[0])  # Normal state: 0\n",
    "        y_fatigue = np.ones(psd_fatigue.shape[0])  # Fatigue state: 1\n",
    "\n",
    "        # Append PSD features and labels\n",
    "        X_features.append(np.hstack((psd_normal[:,:,0], sp_entropy_normal)))\n",
    "        X_features.append(np.hstack((psd_fatigue[:,:,0], sp_entropy_fatigue)))\n",
    "        X_psd.append(psd_normal[:,:,0])\n",
    "        X_psd.append(psd_fatigue[:,:,0])\n",
    "        X_sp_ent.append(sp_entropy_normal)\n",
    "        X_sp_ent.append(sp_entropy_fatigue)\n",
    "        y_features.append(y_normal)\n",
    "        y_features.append(y_fatigue)\n",
    "\n",
    "        # Print processing status\n",
    "        print(f\"Processed Subject {i}: Normal {len(psd_normal)} epochs, Fatigue {len(psd_fatigue)} epochs\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject {i}: {e}\")\n",
    "\n",
    "# Concatenate all subjects' PSD and Spectral Entropy features and labels\n",
    "X_features = np.concatenate(X_features, axis=0)\n",
    "X_psd = np.concatenate(X_psd, axis=0)\n",
    "X_sp_ent = np.concatenate(X_sp_ent, axis=0)\n",
    "y_features = np.concatenate(y_features, axis=0)\n",
    "y_psd = y_features\n",
    "y_sp_ent = y_features\n",
    "X_psd_1 = X_psd\n",
    "\n",
    "# Perform Feature Scaling\n",
    "standard_scaler = StandardScaler()\n",
    "X_features = standard_scaler.fit_transform(X_features)\n",
    "X_psd = standard_scaler.fit_transform(X_psd)\n",
    "X_sp_ent = standard_scaler.fit_transform(X_sp_ent)\n",
    "\n",
    "# Power Spectral Density Features\n",
    "print(f\"PSD Features shape: {X_psd.shape}, Labels shape: {y_psd.shape}\")\n",
    "\n",
    "# Split PSD features into training and testing datasets\n",
    "X_psd_train, X_psd_test, y_psd_train, y_psd_test = train_test_split(\n",
    "    X_psd, y_psd, train_size=0.8, random_state=42, stratify=y_psd)\n",
    "\n",
    "print(\"Power Spectral Density Features\")\n",
    "print(f\"Training data shape: {X_psd_train.shape}, Testing data shape: {X_psd_test.shape}\")\n",
    "\n",
    "# Spectral Entropy Features\n",
    "print(f\"\\nSpectral Entropy Features shape: {X_sp_ent.shape}, Labels shape: {y_sp_ent.shape}\")\n",
    "\n",
    "# Split Spectral Entropy features into training and testing datasets\n",
    "X_sp_ent_train, X_sp_ent_test, y_sp_ent_train, y_sp_ent_test = train_test_split(\n",
    "    X_sp_ent, y_sp_ent, train_size=0.8, random_state=42, stratify=y_sp_ent)\n",
    "\n",
    "print(\"Spectral Entropy Features\")\n",
    "print(f\"Training data shape: {X_sp_ent_train.shape}, Testing data shape: {X_sp_ent_test.shape}\")\n",
    "\n",
    "# Power Spectral Density and Spectral Entropy Features\n",
    "print(f\"\\nPSD and Spectral Entropy Features shape: {X_features.shape}, Labels shape: {y_features.shape}\")\n",
    "\n",
    "# Split PSD and Spectral Entropy features into training and testing datasets\n",
    "X_features_train, X_features_test, y_features_train, y_features_test = train_test_split(\n",
    "    X_features, y_features, train_size=0.8, random_state=42, stratify=y_features)\n",
    "\n",
    "print(\"Power Spectral Density and Spectral Entropy Features\")\n",
    "print(f\"Training data shape: {X_features_train.shape}, Testing data shape: {X_features_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31363d97-1ada-4030-bf7e-d7904691072e",
   "metadata": {},
   "source": [
    "A portion of the normal state and fatigue state raw EEG of each subject and it pre-processed EEG was visualized in individual separate windows. The pre-processing done includes the notch filtering to remove the line noise interference and it was further pre-processed by applying bandpass filter to highlight the delta, theta, alpha, and beta band of the EEG where difference between normal state and fatigue state can be observed. Specifically, at delta and theta band represents the deep meditation and sleep, while alpha and beta shows alertness and consciousness. Next, the feature extraction consist of extracting power spectral density (PSD) and spectral entropy features from the 40 channels of EEG. Datasets were created where one dataset contains PSD features only, one dataset alloted for the spectral entropy only, and a final dataset that includes both features. They were normalized using Standard Scaler. Each set of dataset were then splitted for training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af708fa-6689-4304-a571-7068d757f9cb",
   "metadata": {
    "id": "9af708fa-6689-4304-a571-7068d757f9cb"
   },
   "source": [
    "## Machine Learning Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34085ff8-0220-448d-9591-f54805d058c3",
   "metadata": {
    "id": "34085ff8-0220-448d-9591-f54805d058c3"
   },
   "source": [
    "### Power Spectral Density Features Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b711f77-8d0b-4771-87ef-d311b99e6236",
   "metadata": {
    "id": "5b711f77-8d0b-4771-87ef-d311b99e6236"
   },
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "345cd0c9-da7a-4178-ad35-44c3c59967a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "345cd0c9-da7a-4178-ad35-44c3c59967a0",
    "outputId": "7ff6aabc-e8f0-4008-d890-b636ef71ebf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.6001386001386\n",
      "Average K-Fold Accuracy: 89.34571026804036\n",
      "Execution Time: 11.451846599578857 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.91      0.89      1442\n",
      "     Fatigue       0.90      0.87      0.88      1444\n",
      "\n",
      "    accuracy                           0.89      2886\n",
      "   macro avg       0.89      0.89      0.89      2886\n",
      "weighted avg       0.89      0.89      0.89      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Essential Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import time\n",
    "\n",
    "accuracy_psd = []             #Store Validation Accuracy of PSD feature only\n",
    "kfold_accuracy_psd = []       #Store K-Fold Accuracy of PSD feature only\n",
    "execution_psd = []            #Store Execution Time of PSD feature only\n",
    "\n",
    "# Random Forest Classifier Implementation\n",
    "start = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=250)\n",
    "clf.fit(X_psd_train.reshape(X_psd_train.shape[0], -1), y_psd_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_psd_test.reshape(X_psd_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=clf, X=X_psd, y=y_psd, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_psd_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_psd.append(accuracy)\n",
    "kfold_accuracy_psd.append(accuracies_average)\n",
    "execution_psd.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_psd_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_psd_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='Random Forest - PSD Only')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b159a-0bd6-46c9-b5d9-93293cb601f4",
   "metadata": {
    "id": "2d7b159a-0bd6-46c9-b5d9-93293cb601f4"
   },
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d930c051-c9c2-4e52-8767-4e15582a519d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "d930c051-c9c2-4e52-8767-4e15582a519d",
    "outputId": "ec90bdbf-c5fa-49c7-afec-412c41658c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 63.340263340263334\n",
      "Average K-Fold Accuracy: 63.03178191527705\n",
      "Execution Time: 19.651829957962036 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.59      0.86      0.70      1442\n",
      "     Fatigue       0.74      0.41      0.53      1444\n",
      "\n",
      "    accuracy                           0.63      2886\n",
      "   macro avg       0.67      0.63      0.61      2886\n",
      "weighted avg       0.67      0.63      0.61      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Implementation\n",
    "start = time.time()\n",
    "support_vector_machine = SVC(kernel = 'rbf')\n",
    "support_vector_machine.fit(X_psd_train.reshape(X_psd_train.shape[0], -1), y_psd_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = support_vector_machine.predict(X_psd_test.reshape(X_psd_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=support_vector_machine, X=X_psd, y=y_psd, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_psd_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_psd.append(accuracy)\n",
    "kfold_accuracy_psd.append(accuracies_average)\n",
    "execution_psd.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_psd_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_psd_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='Support Vector Machine - PSD Only')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866e55e4-52ed-478d-8ef4-2e2cea70851a",
   "metadata": {
    "id": "866e55e4-52ed-478d-8ef4-2e2cea70851a"
   },
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aca3ad25-587c-4f6f-ac04-36f688466372",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "b3fab060-d0e8-418c-9bd9-2ce457e0d57c",
    "outputId": "55d024c4-b063-4c85-f65b-4b5598142856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 69.36936936936937\n",
      "Average K-Fold Accuracy: 70.03324673227586\n",
      "Execution Time: 0.2677648067474365 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.69      0.71      0.70      1442\n",
      "     Fatigue       0.70      0.68      0.69      1444\n",
      "\n",
      "    accuracy                           0.69      2886\n",
      "   macro avg       0.69      0.69      0.69      2886\n",
      "weighted avg       0.69      0.69      0.69      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Implementation\n",
    "start = time.time()\n",
    "k_nearest_neighbors = KNeighborsClassifier(n_neighbors=9)\n",
    "k_nearest_neighbors.fit(X_psd_train.reshape(X_psd_train.shape[0], -1), y_psd_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = k_nearest_neighbors.predict(X_psd_test.reshape(X_psd_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=k_nearest_neighbors, X=X_psd, y=y_psd, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_psd_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_psd.append(accuracy)\n",
    "kfold_accuracy_psd.append(accuracies_average)\n",
    "execution_psd.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_psd_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_psd_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='K-Nearest Neighbor - PSD Only')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811c201-7a71-48f2-93d2-0d02647c6570",
   "metadata": {},
   "source": [
    "### Spectral Entropy Features Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5f876-f763-4ec6-913d-703e508c1c9e",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71affbc9-7a98-4136-b6fe-e2289963a87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 99.13374913374913\n",
      "Average K-Fold Accuracy: 99.25135740669721\n",
      "Execution Time: 9.057426691055298 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.99      0.99      0.99      1442\n",
      "     Fatigue       0.99      0.99      0.99      1444\n",
      "\n",
      "    accuracy                           0.99      2886\n",
      "   macro avg       0.99      0.99      0.99      2886\n",
      "weighted avg       0.99      0.99      0.99      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_sp_ent = []             #Store Validation Accuracy of Spectral Entropy feature only\n",
    "kfold_accuracy_sp_ent = []       #Store K-Fold Accuracy of Spectral Entropy feature only\n",
    "execution_sp_ent = []            #Store Execution Time of Spectral Entropy feature only\n",
    "\n",
    "# Random Forest Classifier Implementation\n",
    "start = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=250)\n",
    "clf.fit(X_sp_ent_train.reshape(X_sp_ent_train.shape[0], -1), y_sp_ent_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_sp_ent_test.reshape(X_sp_ent_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=clf, X=X_sp_ent, y=y_sp_ent, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_sp_ent_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_sp_ent.append(accuracy)\n",
    "kfold_accuracy_sp_ent.append(accuracies_average)\n",
    "execution_sp_ent.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_sp_ent_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_sp_ent_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='Random Forest - Spectral Entropy Only')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ddf2b-5fa8-48c3-9957-696ac570af61",
   "metadata": {
    "id": "2d7b159a-0bd6-46c9-b5d9-93293cb601f4"
   },
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc4d3c05-1906-4fd9-9e34-55a7480e7279",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "d930c051-c9c2-4e52-8767-4e15582a519d",
    "outputId": "ec90bdbf-c5fa-49c7-afec-412c41658c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 99.02979902979902\n",
      "Average K-Fold Accuracy: 98.98794986173627\n",
      "Execution Time: 3.6254916191101074 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.99      0.99      0.99      1442\n",
      "     Fatigue       0.99      0.99      0.99      1444\n",
      "\n",
      "    accuracy                           0.99      2886\n",
      "   macro avg       0.99      0.99      0.99      2886\n",
      "weighted avg       0.99      0.99      0.99      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Implementation\n",
    "start = time.time()\n",
    "support_vector_machine = SVC(kernel = 'rbf')\n",
    "support_vector_machine.fit(X_sp_ent_train.reshape(X_sp_ent_train.shape[0], -1), y_sp_ent_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = support_vector_machine.predict(X_sp_ent_test.reshape(X_sp_ent_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=support_vector_machine, X=X_sp_ent, y=y_sp_ent, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_sp_ent_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_sp_ent.append(accuracy)\n",
    "kfold_accuracy_sp_ent.append(accuracies_average)\n",
    "execution_sp_ent.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_sp_ent_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_sp_ent_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='Support Vector Machine - Spectral Entropy Only')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5c65c-9139-4940-ab73-2c44e92b958a",
   "metadata": {
    "id": "866e55e4-52ed-478d-8ef4-2e2cea70851a"
   },
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4f1da2-bc30-4dce-84e3-c0e73eaf86f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "b3fab060-d0e8-418c-9bd9-2ce457e0d57c",
    "outputId": "55d024c4-b063-4c85-f65b-4b5598142856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 97.85169785169785\n",
      "Average K-Fold Accuracy: 98.03822172754211\n",
      "Execution Time: 0.07373595237731934 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.97      0.99      0.98      1442\n",
      "     Fatigue       0.99      0.97      0.98      1444\n",
      "\n",
      "    accuracy                           0.98      2886\n",
      "   macro avg       0.98      0.98      0.98      2886\n",
      "weighted avg       0.98      0.98      0.98      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Implementation\n",
    "start = time.time()\n",
    "k_nearest_neighbors = KNeighborsClassifier(n_neighbors=9)\n",
    "k_nearest_neighbors.fit(X_sp_ent_train.reshape(X_sp_ent_train.shape[0], -1), y_sp_ent_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = k_nearest_neighbors.predict(X_sp_ent_test.reshape(X_sp_ent_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=k_nearest_neighbors, X=X_sp_ent, y=y_sp_ent, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_sp_ent_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_sp_ent.append(accuracy)\n",
    "kfold_accuracy_sp_ent.append(accuracies_average)\n",
    "execution_sp_ent.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_sp_ent_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_sp_ent_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='K-Nearest Neighbor - Spectral Entropy Only')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019897f7-021d-45a3-8171-24c4154114a2",
   "metadata": {},
   "source": [
    "### Power Spectral Density and Spectral Entropy Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3b5bc-2a79-48fe-85a3-b590e3d40e79",
   "metadata": {
    "id": "5b711f77-8d0b-4771-87ef-d311b99e6236"
   },
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d29528-3bb9-4f8f-8fae-0ccdd47d3fac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "345cd0c9-da7a-4178-ad35-44c3c59967a0",
    "outputId": "7ff6aabc-e8f0-4008-d890-b636ef71ebf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 99.68814968814968\n",
      "Average K-Fold Accuracy: 99.48013414032832\n",
      "Execution Time: 11.363505363464355 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00      1442\n",
      "     Fatigue       1.00      1.00      1.00      1444\n",
      "\n",
      "    accuracy                           1.00      2886\n",
      "   macro avg       1.00      1.00      1.00      2886\n",
      "weighted avg       1.00      1.00      1.00      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_features = []             #Store Validation Accuracy of PSD and Spectral Entropy features\n",
    "kfold_accuracy_features = []       #Store K-Fold Accuracy of PSD and Spectral Entropy features\n",
    "execution_features = []            #Store Execution Time of PSD and Spectral Entropy features\n",
    "\n",
    "# Random Forest Classifier Implementation\n",
    "start = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=250)\n",
    "clf.fit(X_features_train.reshape(X_features_train.shape[0], -1), y_features_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_features_test.reshape(X_features_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=clf, X=X_features, y=y_features, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_features_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_features.append(accuracy)\n",
    "kfold_accuracy_features.append(accuracies_average)\n",
    "execution_features.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_features_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_features_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='Random Forest - PSD and Spectral Entropy')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c724fe4-05a1-4cce-97a4-214079e71a33",
   "metadata": {
    "id": "2d7b159a-0bd6-46c9-b5d9-93293cb601f4"
   },
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6602ca6d-bc56-47ee-bb06-090d53fdfcb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "d930c051-c9c2-4e52-8767-4e15582a519d",
    "outputId": "ec90bdbf-c5fa-49c7-afec-412c41658c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 98.30214830214831\n",
      "Average K-Fold Accuracy: 98.12838871091299\n",
      "Execution Time: 6.865126609802246 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.99      0.98      0.98      1442\n",
      "     Fatigue       0.98      0.99      0.98      1444\n",
      "\n",
      "    accuracy                           0.98      2886\n",
      "   macro avg       0.98      0.98      0.98      2886\n",
      "weighted avg       0.98      0.98      0.98      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Implementation\n",
    "start = time.time()\n",
    "support_vector_machine = SVC(kernel = 'rbf')\n",
    "support_vector_machine.fit(X_features_train.reshape(X_features_train.shape[0], -1), y_features_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = support_vector_machine.predict(X_features_test.reshape(X_features_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=support_vector_machine, X=X_features, y=y_features, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_features_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_features.append(accuracy)\n",
    "kfold_accuracy_features.append(accuracies_average)\n",
    "execution_features.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_features_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_features_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='Support Vector Machine - PSD and Spectral Entropy')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33d56f-c73d-4b22-83f7-e31584fc0b7b",
   "metadata": {
    "id": "866e55e4-52ed-478d-8ef4-2e2cea70851a"
   },
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6759a9f9-3968-4704-84bb-5e604394d7d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "b3fab060-d0e8-418c-9bd9-2ce457e0d57c",
    "outputId": "55d024c4-b063-4c85-f65b-4b5598142856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 97.22799722799724\n",
      "Average K-Fold Accuracy: 97.08857529245878\n",
      "Execution Time: 0.06991767883300781 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.96      0.98      0.97      1442\n",
      "     Fatigue       0.98      0.96      0.97      1444\n",
      "\n",
      "    accuracy                           0.97      2886\n",
      "   macro avg       0.97      0.97      0.97      2886\n",
      "weighted avg       0.97      0.97      0.97      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Implementation\n",
    "start = time.time()\n",
    "k_nearest_neighbors = KNeighborsClassifier(n_neighbors=9)\n",
    "k_nearest_neighbors.fit(X_features_train.reshape(X_features_train.shape[0], -1), y_features_train)  # Flatten features\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = k_nearest_neighbors.predict(X_features_test.reshape(X_features_test.shape[0], -1))  # Flatten features\n",
    "end = time.time()\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "K_Fold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = cross_val_score(estimator=k_nearest_neighbors, X=X_features, y=y_features, cv=K_Fold, scoring='accuracy')\n",
    "accuracies_average = accuracies.mean()\n",
    "\n",
    "# Calculate accuracy and runtime\n",
    "accuracy = accuracy_score(y_features_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy*100}\")\n",
    "print(f\"Average K-Fold Accuracy: {accuracies_average*100}\")\n",
    "runtime = (end-start)   # Execution Runtime\n",
    "print(f\"Execution Time: {runtime} s\")\n",
    "accuracy_features.append(accuracy)\n",
    "kfold_accuracy_features.append(accuracies_average)\n",
    "execution_features.append(runtime)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_features_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_features_test, y_pred, target_names=[\"Normal\", \"Fatigue\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(10,7), num='K-Nearest Neighbor - PSD and Spectral Entropy')\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Fatigue\"], yticklabels=[\"Normal\", \"Fatigue\"])\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09137e-f8eb-4c35-8eff-1392d1a93ad3",
   "metadata": {},
   "source": [
    "#### Comparison of Validation Accuracy, K-Fold Accuracy, and Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d0edc3c-96ac-4b14-9b00-19a9dbb60b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Random Forest\", \"SVM\", \"KNN\"]                            # Set as X values\n",
    "X_axis = np.arange(len(models)) \n",
    "\n",
    "# Plot the Comparison of Testing Accuracy\n",
    "plt.figure(figsize=(10,7), num='Comparison of Testing Accuracy')\n",
    "plt.bar(X_axis-0.3, accuracy_psd, 0.3, label=\"PSD only\")\n",
    "plt.bar(X_axis, accuracy_sp_ent, 0.3, label=\"Spectral Entropy only\")\n",
    "plt.bar(X_axis+0.3, accuracy_features, 0.3, label=\"Both Features\")\n",
    "plt.xticks(X_axis, models) \n",
    "plt.xlabel(\"Machine Learning Model\")\n",
    "plt.ylabel(\"Testing Accuracy (%)\")\n",
    "plt.title(\"Comparison of Testing Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Comparison of K-Fold Accuracy\n",
    "plt.figure(figsize=(10,7), num='Comparison of K-Fold Accuracy')\n",
    "plt.bar(X_axis-0.3, kfold_accuracy_psd, 0.3, label=\"PSD only\")\n",
    "plt.bar(X_axis, kfold_accuracy_sp_ent, 0.3, label=\"Spectral Entropy only\")\n",
    "plt.bar(X_axis+0.3, kfold_accuracy_features, 0.3, label=\"Both Features\")\n",
    "plt.xticks(X_axis, models) \n",
    "plt.xlabel(\"Machine Learning Model\")\n",
    "plt.ylabel(\"K-Fold Accuracy (%)\")\n",
    "plt.title(\"Comparison of K-Fold Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Comparison of Execution Time\n",
    "plt.figure(figsize=(10,7), num='Comparison of Execution Time')\n",
    "plt.bar(X_axis-0.3, execution_psd, 0.3, label=\"PSD only\")\n",
    "plt.bar(X_axis, execution_sp_ent, 0.3, label=\"Spectral Entropy only\")\n",
    "plt.bar(X_axis+0.3, execution_features, 0.3, label=\"Both Features\")\n",
    "plt.xticks(X_axis, models) \n",
    "plt.xlabel(\"Machine Learning Model\")\n",
    "plt.ylabel(\"Execution Time (s)\")\n",
    "plt.title(\"Comparison of Execution Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f935635-f3e8-434b-a71e-c97b1e0de4eb",
   "metadata": {},
   "source": [
    "The output of the model predictions shows that when using PSD features alone, relative low accuracy is achieved and showed the longest average runtime. When using the Spectral entropy features alone, the accuracy and runtime are greatly improved, in fact in garnered the highest average accuracy and shortest runtime among the three datasets used. Finally when using both features, the accuracy and runtime were close to when using spectral entropy alone, however, the accuracy slightly decreased and the runtime increased by a small factor. It must be noted that the highest accuracy among all the model implementation was achieved when using both features paired with random forest classifier. Analyzing the trend of model predictions, it showed that the spectral entropy of driver's EEG alone shows a promising potential in detecting fatigue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cba125-e238-43b9-9adb-24c60b622612",
   "metadata": {},
   "source": [
    "#### ***Average PSD per Frequency Range***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7055315e-a74c-467a-bb14-7868dc1c50b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch detected: freqs length (45) does not match X_psd frequency axis (40).\n"
     ]
    }
   ],
   "source": [
    "# Frequency bands\n",
    "bands = {'Delta (0.5-4 Hz)': (0.5, 4),\n",
    "         'Theta (4-8 Hz)': (4, 8),\n",
    "         'Alpha (8-13 Hz)': (8, 13),\n",
    "         'Beta (13-30 Hz)': (13, 30)}\n",
    "\n",
    "# Storage\n",
    "avg_psd_normal = []\n",
    "avg_psd_fatigue = []\n",
    "\n",
    "# Ensure band_idx matches the frequency dimension of X_psd\n",
    "if len(freqs) != X_psd_1.shape[1]:\n",
    "    print(f\"Mismatch detected: freqs length ({len(freqs)}) does not match X_psd frequency axis ({X_psd_1.shape[1]}).\")\n",
    "    freqs = freqs[:X_psd_1.shape[1]]  # Truncate freqs to match X_psd\n",
    "\n",
    "# Loop through frequency bands and compute averages\n",
    "for band, (low, high) in bands.items():\n",
    "    band_idx = (freqs >= low) & (freqs <= high)  # Indices for the current band\n",
    "    \n",
    "    # Average PSD for the current band\n",
    "    avg_psd_normal.append(X_psd_1[y_psd == 0][:, band_idx].mean(axis=1).mean())\n",
    "    avg_psd_fatigue.append(X_psd_1[y_psd == 1][:, band_idx].mean(axis=1).mean())\n",
    "\n",
    "# Bar plot\n",
    "x = range(len(bands))  # Indices for bars\n",
    "plt.figure(figsize=(10,7), num='Average PSD Across Frequency Bands')\n",
    "plt.bar(x, avg_psd_normal, width=0.4, label='Normal (Non-Sleepy)', color='blue', alpha=0.7)\n",
    "plt.bar([i + 0.4 for i in x], avg_psd_fatigue, width=0.4, label='Fatigue (Sleepy)', color='red', alpha=0.7)\n",
    "plt.xticks([i + 0.2 for i in x], bands.keys(), rotation=45)\n",
    "plt.title('Average PSD Across Frequency Bands')\n",
    "plt.xlabel('Frequency Band')\n",
    "plt.ylabel('Average Power (PSD)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dff704-4f21-44bb-98b9-894c6383dafa",
   "metadata": {},
   "source": [
    "As part of the results, the average power spectral density of each state is compared per frequency range to discern if there is distinction between them. It shows that in the delta band, there is not that much difference between the PSD of the states. In the other bands, difference between the states were observed specifically, at theta band, the normal state had a higher PSD, while on the alpha and beta band, it was noted that fatigue state have a higher PSD. High PSD means that the power is distibuted across the specified range of frequencies. It can be interpreted that in the theta band which signifies the behavior of deep meditation, the normal state showed varied power levels however in the fatigue state the power levels of EEG are not varied meaning they are clustered. On the other hand, in the alpha and beta band which signifies consciousness, the normal state is the clustered one which depicts calm and tranquil response while the high PSD of fatigue state may mean that they are battling the sleepiness they are experiencing."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
